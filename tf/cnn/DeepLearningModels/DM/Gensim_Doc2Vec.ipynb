{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from gensim.models import doc2vec\n",
      "from collections import namedtuple\n",
      "\n",
      "import csv\n",
      "import re\n",
      "import string\n",
      "\n",
      "reader = csv.reader(open(\"wikipedia.csv\"))\n",
      "count = 0\n",
      "data = ''\n",
      "for row in reader:\n",
      "    count = count + 1\n",
      "    if count > 301:\n",
      "       break\n",
      "    else:\n",
      "        data += row[1]\n",
      "        \n",
      "sentenceEnders = re.compile('[.?!]')\n",
      "data_list = sentenceEnders.split(data)\n",
      "\n",
      "LabelDoc = namedtuple('LabelDoc', 'words tags')\n",
      "exclude = set(string.punctuation)\n",
      "all_docs = []\n",
      "count = 0\n",
      "for sen in data_list:\n",
      "    word_list = sen.split()\n",
      "    if len(word_list) < 3:\n",
      "        continue\n",
      "    tag = ['SEN_' + str(count)]\n",
      "    count += 1\n",
      "    sen = ''.join(ch for ch in sen if ch not in exclude)\n",
      "    all_docs.append(LabelDoc(sen.split(), tag))\n",
      "    \n",
      "print all_docs[0:10]\n",
      "    \n",
      "model = doc2vec.Doc2Vec(alpha=0.025, min_alpha=0.025)  # use fixed learning rate\n",
      "model.build_vocab(all_docs)\n",
      "for epoch in range(10):\n",
      "    model.train(all_docs)\n",
      "    model.alpha -= 0.002  # decrease the learning rate\n",
      "    model.min_alpha = model.alpha  # fix the learning rate, no decay    \n",
      "\n",
      "model.save('my_model.doc2vec')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[LabelDoc(words=['Research', 'Design', 'and', 'Standards', 'Organization', 'The', 'Research', 'Design', 'and', 'Standards', 'Organisation', 'RDSO', 'is', 'an', 'ISO', '9001', 'research', 'and', 'development', 'organisation', 'under', 'the', 'Ministry', 'of', 'Railways', 'of', 'India', 'which', 'functions', 'as', 'a', 'technical', 'adviser', 'and', 'consultant', 'to', 'the', 'Railway', 'Board', 'the', 'Zonal', 'Railways', 'the', 'Railway', 'Production', 'Units', 'RITES', 'and', 'IRCON', 'International', 'in', 'respect', 'of', 'design', 'and', 'standardisation', 'of', 'railway', 'equipment', 'and', 'problems', 'related', 'to', 'railway', 'construction', 'operation', 'and', 'maintenance'], tags=['SEN_0']), LabelDoc(words=['To', 'enforce', 'standardisation', 'and', 'coordination', 'between', 'various', 'railway', 'systems', 'in', 'British', 'India', 'the', 'Indian', 'Railway', 'Conference', 'Association', 'IRCA', 'was', 'set', 'up', 'in', '1903'], tags=['SEN_1']), LabelDoc(words=['It', 'was', 'followed', 'by', 'the', 'establishment', 'of', 'the', 'Central', 'Standards', 'Office', 'CSO', 'in', '1930', 'for', 'preparation', 'of', 'designs', 'standards', 'and', 'specifications'], tags=['SEN_2']), LabelDoc(words=['However', 'till', 'independence', 'in', '1947', 'most', 'of', 'the', 'designs', 'and', 'manufacture', 'of', 'railway', 'equipments', 'was', 'entrusted', 'to', 'foreign', 'consultants'], tags=['SEN_3']), LabelDoc(words=['After', 'independence', 'a', 'new', 'organisation', 'called', 'Railway', 'Testing', 'and', 'Research', 'Centre', 'RTRC', 'was', 'set', 'up', 'in', '1952', 'at', 'Lucknow', 'for', 'undertaking', 'intensive', 'investigation', 'of', 'railway', 'problems', 'providing', 'basic', 'criteria', 'and', 'new', 'concepts', 'for', 'design', 'purposes', 'for', 'testing', 'prototypes', 'and', 'generally', 'assisting', 'in', 'finding', 'solutions', 'for', 'specific', 'problems'], tags=['SEN_4']), LabelDoc(words=['In', '1957', 'the', 'Central', 'Standards', 'Office', 'CSO', 'and', 'the', 'Railway', 'Testing', 'and', 'Research', 'Centre', 'RTRC', 'were', 'integrated', 'into', 'a', 'single', 'unit', 'named', 'Research', 'Designs', 'and', 'Standards', 'Organisation', 'RDSO', 'under', 'the', 'Ministry', 'of', 'Railways', 'with', 'its', 'headquarters', 'at', 'Manaknagar', 'Lucknow'], tags=['SEN_5']), LabelDoc(words=['The', 'status', 'of', 'RDSO', 'was', 'changed', 'from', 'an', 'Attached', 'Office', 'to', 'a', 'Zonal', 'Railway', 'on', 'April', '1', '2003', 'to', 'give', 'it', 'greater', 'flexibility', 'and', 'a', 'boost', 'to', 'the', 'research', 'and', 'development', 'activities'], tags=['SEN_6']), LabelDoc(words=['The', 'RDSO', 'is', 'headed', 'by', 'a', 'Director', 'General', 'who', 'ranks', 'with', 'a', 'General', 'Manager', 'of', 'a', 'Zonal', 'Railway'], tags=['SEN_7']), LabelDoc(words=['The', 'Director', 'General', 'is', 'assisted', 'by', 'an', 'Additional', 'Director', 'General', 'and', '23', 'Sr'], tags=['SEN_8']), LabelDoc(words=['Executive', 'Directors', 'and', 'Executive', 'Directors', 'who', 'are', 'in', 'charge', 'of', 'the', '27', 'directorates', 'Bridges', 'and', 'Structures', 'the', 'Centre', 'for', 'Advanced', 'Maintenance', 'Techlogy', 'AMTECH', 'Carriage', 'Geotechnical', 'Engineering', 'Testing', 'Track', 'Design', 'Medical', 'EMU', 'Power', 'Supply', 'Engine', 'Development', 'Finance', 'Accounts', 'Telecommunication', 'Quality', 'Assurance', 'Personnel', 'Works', 'PsychoTechnical', 'Research', 'Signal', 'Wagon', 'Design', 'Electric', 'Locomotive', 'Stores', 'Track', 'Machines', 'Monitoring', 'Traction', 'Installation', 'Energy', 'Management', 'Traffic', 'Metallurgical', 'Chemical', 'Motive', 'Power', 'and', 'Library', 'Publications'], tags=['SEN_9'])]\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import random\n",
      "import numpy as np\n",
      "import string\n",
      "\n",
      "\n",
      "doc_id = np.random.randint(model.docvecs.count) \n",
      "print doc_id\n",
      "\n",
      "sims = model.docvecs.most_similar(doc_id, topn=model.docvecs.count)\n",
      "print('TARGET' , all_docs[doc_id].words)\n",
      "\n",
      "count = 0\n",
      "for i in sims:\n",
      "    if count > 8:\n",
      "        break\n",
      "    pid = int(string.replace(i[0], \"SEN_\", \"\"))\n",
      "    print(i[0],\": \", all_docs[pid].words)\n",
      "    count += 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "11542\n",
        "('TARGET', ['Maldonado', 'holds', 'two', 'notable', 'knockout', 'victories', 'over', 'Maiquel', 'Falc\\xc3\\xa3o'])"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('SEN_8152', ': ', ['Maldonado', 'was', 'expected', 'to', 'face', 'Aaron', 'Rosa', 'at'])\n",
        "('SEN_8147', ': ', ['Notable', 'victories', 'from', 'this', 'period', 'include', 'Jessie', 'Gibbs', 'Vitor', 'Miranda', 'and', 'two', 'TKO', 'victories', 'over', 'Maiquel', 'Falc\\xc3\\xa3o'])\n",
        "('SEN_3945', ': ', ['Wright', 'Zoological', 'Museum', 'Emily', 'Graslie'])\n",
        "('SEN_10040', ': ', ['Green', 'Professor', 'John', 'B'])\n",
        "('SEN_6144', ': ', ['British', 'blues', 'boom'])\n",
        "('SEN_6045', ': ', ['Ohio', 'State', 'went', '6\\xe2\\x80\\x933', 'during', 'this', 'period'])\n",
        "('SEN_10981', ': ', ['Morrison', 'was', 'knocked', 'out', 'in', 'the', 'sixth', 'round'])\n",
        "('SEN_6295', ': ', ['Australia', 'and', 'New', 'Zealand'])\n",
        "('SEN_7465', ': ', ['1434', 'CE', 'called', 'QutbulMadar', 'and', 'is', 'centered', 'around', 'his', 'shrine', 'dargah', 'at', 'Makanpur', 'Kanpur', 'district', 'Uttar', 'Pradesh'])\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}